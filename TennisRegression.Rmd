---
title: "Regression Project"
author: "Fiona Dunn"
date: "6/22/2020"
output: html_document
---

```{r}
library("tidyverse")
tennis <- tennis_2013_2017_GS
tennis <- as_tibble(tennis)
```

```{r}
tennis_data_cleaned <- tennis_2013_2017_GS %>% 
  select(-c("w_n_netpt_w", "w_n_netpt", "slam", "player1", "player2", "a1", "a2", "match_id.y")) %>% 
  rename(Net_points = l_n_netpt,
         Net_points_won = l_n_netpt_w) %>% 
  mutate(w_bp_success = w_n_bp_w/w_n_bp,
         l_bp_success = l_n_bp_w/l_n_bp,
         w_sv_success = w_n_sv_w/w_n_sv,
         l_sv_success = l_n_sv_w/l_n_sv,
         upset_bool = ifelse(winner_rank >loser_rank, TRUE, FALSE)) %>% 
  filter(Retirement == FALSE) %>% 
  filter(w_setswon %in% c(2,3))
```

EDA Histogram
We later picked w_pointswon to be our response with the following filters
```{r}
tennis_data_cleaned %>%
  filter(w_pointswon > 50 & w_pointswon < 200) %>%
  ggplot(aes(x = w_pointswon)) +
  geom_histogram(color = "black", 
                 fill = "darkblue",
                 alpha = 0.3) +
  theme_bw()
```


Scatter plots for EDA
```{r}
##Points Won for Winners v Winner Number Serves Won
tennis_data_cleaned %>%
  ggplot(aes(x = w_n_sv_w,
             y = w_pointswon)) +
  geom_point() +
  geom_smooth()

cor(tennis_data_cleaned$w_pointswon, tennis_data_cleaned$w_n_sv_w)

##Points Won for Winners v w_n_sv
tennis_data_cleaned %>%
  ggplot(aes(x = w_n_sv,
             y = w_pointswon)) +
  geom_point() +
  geom_smooth()

cor(tennis_data_cleaned$w_pointswon, tennis_data_cleaned$w_n_sv)

##Points Won for Winners v l_n_sv_w
tennis_data_cleaned %>%
  ggplot(aes(x = l_n_sv_w,
             y = w_pointswon)) +
  geom_point() +
  geom_smooth()

cor(tennis_data_cleaned$w_pointswon, tennis_data_cleaned$l_n_sv_w)

##Points Won for Winners v l_n_ue
tennis_data_cleaned %>%
  ggplot(aes(x = l_n_ue,
             y = w_pointswon)) +
  geom_point() +
  geom_smooth()

cor(tennis_data_cleaned$w_pointswon, tennis_data_cleaned$l_n_ue)


##Points Won for Winners v l_n_sv
tennis_data_cleaned %>%
  ggplot(aes(x = l_n_sv,
             y = w_pointswon)) +
  geom_point() +
  geom_smooth()

cor(tennis_data_cleaned$w_pointswon, tennis_data_cleaned$l_n_sv)

```


VARIABLE SELECTION
can see that w_n_sv_w, w_n_sv, l_n_sv, l_n_sv_w are all high cor 
```{r}
library(ggcorrplot)
tennis_model_data <- tennis_data_cleaned %>%
  dplyr::select(w_n_winners, 
                l_n_sv_w,
                w_n_sv_w,
                w_pointswon,
                w_n_ue,
                l_n_ue,
                w_n_sv,
                l_n_sv)
tennis_cor_matrix <- cor(tennis_model_data)
ggcorrplot(tennis_cor_matrix)


round_cor_matrix <- 
  round(cor(tennis_model_data), 2)
ggcorrplot(round_cor_matrix, 
           hc.order = TRUE,
           type = "lower",
           lab = TRUE)
```


clustering using matrix (using w_n_winners as y)
clear that w_n_sv_w, w_n_sv, l_n_sv, l_n_sv_w are all correlated to each other as expected
```{r}

tennis_ex_vars <- dplyr::select(tennis_model_data, -w_pointswon)

exp_cor_matrix <- cor(tennis_ex_vars)

cor_dist_matrix <- 1 - abs(exp_cor_matrix)
cor_dist_matrix <- as.dist(cor_dist_matrix)

library(ggdendro)
tennis_exp_hc <- hclust(cor_dist_matrix,
                     "complete") 
ggdendrogram(tennis_exp_hc,
             rotate = TRUE,
             size = 2)
             
library(dendextend)
cor_dist_matrix %>%
  hclust() %>%
  as.dendrogram() %>%
  set("branches_k_col", 
      k = 2) %>% 
  set("labels_cex", .9) %>%
  ggplot(horiz = TRUE)
  
```

Pairs Plot
Clear that w_n_sv_w and w_gameswon are highly corr
```{r}
library(GGally)
tennis_data_linear <- tennis_data_cleaned %>% 
  filter((w_pointswon > 50) & (w_pointswon < 200))

ggpairs(tennis_data_linear,
        columns =
          c("w_n_ue", "l_n_ue", "w_n_winners", "w_n_sv_w", "w_gameswon"),
        mapping = aes(alpha = 0.2)) +
  theme_bw()
```

Creating a linear model 
```{r}
init_w_pointswon <- lm(w_pointswon ~ w_n_winners + w_n_ue + l_n_ue + w_gameswon, tennis_data_linear)
summary(init_w_pointswon)

library(car)
vif(init_w_pointswon)
## w_n_winners and w_gameswon are nearing five

```

Training data
```{r}
set.seed(4345)
n_players <- nrow(tennis_data_linear)
train_i <- sample(n_players, n_players * 0.7, replace = FALSE)
test_i <- (1:n_players)[-train_i]
tennis_train <- tennis_data_linear[train_i,]
tennis_test <- tennis_data_linear[test_i,]
```

Here we came up with a few models that would predict w_pointswon
```{r}
candidate_model_1 <-  lm(w_pointswon ~ w_n_winners + w_n_ue + l_n_ue + w_gameswon, tennis_train)

candidate_model_2 <- lm(w_pointswon ~ w_n_winners + w_n_ue + l_n_ue,
                        data = tennis_train)

candidate_model_3 <-lm(w_pointswon ~ w_n_winners + w_n_ue + Tour + l_n_ue + w_gameswon, tennis_train)

candidate_model_3 <-lm(w_pointswon ~ w_n_winners + w_n_ue + Tour + l_n_ue + w_gameswon, tennis_train)

candidate_model_4 <-lm(w_pointswon ~ w_n_winners + Tour*tournament + w_n_ue + l_n_ue + w_gameswon, tennis_train)
summary(candidate_model_4)

candidate_model_5 <-  lm(w_pointswon ~ w_n_winners + w_n_ue + l_n_ue + w_n_sv_w, tennis_train)
summary(candidate_model_5)
```

Checking MSE

Model 2 has a much higer MSE so no need to move further with it.
```{r}
model_1_preds <- predict(candidate_model_1, newdata = tennis_test)
model_1_mse <- mean((model_1_preds - tennis_test$w_pointswon)^2)
model_1_mse

model_2_preds <- predict(candidate_model_2, newdata = tennis_test)
model_2_mse <- mean((model_2_preds - tennis_test$w_pointswon)^2)
model_2_mse

model_3_preds <- predict(candidate_model_3, newdata = tennis_test)
model_3_mse <- mean((model_3_preds - tennis_test$w_pointswon)^2)
model_3_mse


model_4_preds <- predict(candidate_model_4, newdata = tennis_test)
model_4_mse <- mean((model_4_preds - tennis_test$w_pointswon)^2)
model_4_mse
```


